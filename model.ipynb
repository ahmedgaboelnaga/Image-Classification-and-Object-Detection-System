{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc25a53",
   "metadata": {},
   "source": [
    "# Image Classification and Object Detection System\n",
    "---\n",
    "\n",
    "**Project Overview:**\n",
    "The Image Classification and Object Detection System aims to build a deep learning-based solution for\n",
    "classifying images into predefined categories and detecting objects within images. The project will leverage\n",
    "powerful machine learning frameworks like TensorFlow, Keras, and PyTorch, and integrate cloud tools such\n",
    "as Azure for scalability and real-time deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d30eca",
   "metadata": {},
   "source": [
    "### Milestone 1: Data Collection, Preprocessing, and Exploration\n",
    "\n",
    "---\n",
    "#### Objectives:\n",
    "â€¢ Collect, preprocess, and explore datasets suitable for both image classification and object detection tasks.\n",
    "\n",
    "#### Tasks:\n",
    "1. Data Collection:\n",
    "   - Gather labeled datasets for image classification (e.g., CIFAR-10, ImageNet) and annotated datasets for object detection (e.g., COCO, Pascal VOC).\n",
    "   - Ensure the data includes diverse classes and various object types to support robust model training.\n",
    "2. Data Preprocessing:\n",
    "   - Resize, normalize, and augment images to prepare them for deep learning models.\n",
    "   - Implement augmentation techniques such as rotations, flips, and color jittering to increase model robustness.\n",
    "   - Split datasets into training, validation, and test sets.\n",
    "3. Exploratory Data Analysis (EDA):\n",
    "   - Visualize sample images, class distributions, and bounding box annotations for object detection. \n",
    "   - Investigate any data imbalances or biases in the dataset, such as class imbalance or poor quality annotations.\n",
    "\n",
    "\n",
    "#### Deliverables:\n",
    "- **Cleaned and Preprocessed Image Dataset:** A fully processed dataset ready for model development.\n",
    "- **Preprocessing Pipeline Documentation:** Detailed description of data augmentation techniques and transformations applied.\n",
    "- **EDA Report:** A comprehensive exploration of the dataset, including visualizations and identified challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d7387c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"d3MLo2NB1dQqNnASBgPJ\")\n",
    "project = rf.workspace(\"computer-vision-wi0v7\").project(\"brain-tumor-detection-7aotn\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61081679",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d9b5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Path to Roboflow-exported dataset\n",
    "data_dir = \"/kaggle/input/brain-tumor-detection-dataset\"  # Update this after uploading\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "valid_dir = os.path.join(data_dir, \"valid\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# Load example images and annotations\n",
    "def load_sample_images_with_boxes(split_dir, num_samples=5):\n",
    "    image_paths = glob(os.path.join(split_dir, \"images\", \"*.jpg\"))\n",
    "    label_paths = glob(os.path.join(split_dir, \"labels\", \"*.txt\"))\n",
    "\n",
    "    for image_path in image_paths[:num_samples]:\n",
    "        label_path = image_path.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = img.shape\n",
    "\n",
    "        # Plot bounding boxes\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                cls, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                x1 = int((x_center - width / 2) * w)\n",
    "                y1 = int((y_center - height / 2) * h)\n",
    "                x2 = int((x_center + width / 2) * w)\n",
    "                y2 = int((y_center + height / 2) * h)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "                cv2.putText(img, str(int(cls)), (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Sample with annotations: {os.path.basename(image_path)}\")\n",
    "        plt.show()\n",
    "\n",
    "# Visualize samples from train set\n",
    "load_sample_images_with_boxes(train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c536f55",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c184f254",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
